{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports, Parameters, and Object Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# Setting the expected chessboard pattern size (number of inner corners)\n",
    "pattern_size = (9, 6)\n",
    "square_size = 21.7  # length of each square in mm\n",
    "\n",
    "# Preparing the object points (3D points in the chessboard coordinate system)\n",
    "objp = np.zeros((pattern_size[0]*pattern_size[1], 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1, 2)\n",
    "objp *= square_size\n",
    "\n",
    "# Lists to store all object points and image points\n",
    "object_points_all = []   # 3D points in real-world space\n",
    "image_points_all = []    # 2D points in the image plane\n",
    "\n",
    "# For images that were processed automatically\n",
    "object_points_auto = []\n",
    "image_points_auto = []\n",
    "\n",
    "training_files = glob.glob('training_images/*.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for corner detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOICE 5: Enhance input for automatic detection\n",
    "# Function that enhances the input image to improve automatic chessboard corner detection\n",
    "def preprocess_image(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_eq = cv2.equalizeHist(gray)\n",
    "    gray_blur = cv2.medianBlur(gray_eq, 5)\n",
    "    return gray_blur\n",
    "\n",
    "# Function that allows automatic inner corner detection using OpenCV's chessboard detection functions\n",
    "def detect_corners_automatically(img, pattern_size):\n",
    "    preprocessed = preprocess_image(img)\n",
    "    try:\n",
    "        ret, corners = cv2.findChessboardCornersSB(preprocessed, pattern_size, None)\n",
    "    except Exception:\n",
    "        # Fall back to findChessboardCorners with flags if findChessboardCornersSB is unavailable\n",
    "        flags = cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_NORMALIZE_IMAGE\n",
    "        ret, corners = cv2.findChessboardCorners(preprocessed, pattern_size, flags)\n",
    "    return ret, corners\n",
    "\n",
    "# Function that provides an interactive manual annotation interface\n",
    "# Choice 3: Improves the localization of the four corner points by providing zoomed-in feedback, undo, and confirmation\n",
    "def get_manual_corners(img):\n",
    "    clicked_points = []\n",
    "    img_copy = img.copy()\n",
    "    original_img = img.copy()  # used to redraw the image after undo\n",
    "\n",
    "    # Function to update the display of the manual annotation window\n",
    "    def update_display():\n",
    "        nonlocal img_copy\n",
    "        img_copy = original_img.copy()\n",
    "        for pt in clicked_points:\n",
    "            cv2.circle(img_copy, (int(pt[0]), int(pt[1])), 5, (0, 0, 255), -1)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cv2.putText(img_copy, f\"{int(pt[0])},{int(pt[1])}\", (int(pt[0]), int(pt[1])),\n",
    "                        font, 0.5, (0, 0, 255), 1)\n",
    "        cv2.imshow(\"Manual Annotation\", img_copy)\n",
    "\n",
    "     # Function that displays a zoomed-in view to help the user click more precisely\n",
    "    def zoom_click_refinement(img, point, zoom_factor=4, window_size=400):\n",
    "        x, y = int(point[0]), int(point[1])\n",
    "        h, w = img.shape[:2]\n",
    "        half = window_size // 2\n",
    "        x1 = max(x - half, 0)\n",
    "        y1 = max(y - half, 0)\n",
    "        x2 = min(x + half, w)\n",
    "        y2 = min(y + half, h)\n",
    "        roi = img[y1:y2, x1:x2]\n",
    "        zoomed = cv2.resize(roi, (roi.shape[1]*zoom_factor, roi.shape[0]*zoom_factor))\n",
    "        win_name = \"Zoomed Refinement\"\n",
    "        cv2.namedWindow(win_name, cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(win_name, zoomed)\n",
    "        refined_point = None\n",
    "\n",
    "        # Callback function for the zoomed-in refinement window\n",
    "        def zoom_callback(event, zx, zy, flags, param):\n",
    "            nonlocal refined_point\n",
    "            if event == cv2.EVENT_LBUTTONDOWN:\n",
    "                rx = zx / zoom_factor\n",
    "                ry = zy / zoom_factor\n",
    "                refined_point = (x1 + rx, y1 + ry)\n",
    "                cv2.destroyWindow(win_name)\n",
    "\n",
    "        cv2.setMouseCallback(win_name, zoom_callback)\n",
    "        while refined_point is None:\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == 27:  # Esc cancels refinement\n",
    "                refined_point = point\n",
    "                cv2.destroyWindow(win_name)\n",
    "                break\n",
    "        return refined_point\n",
    "    \n",
    "    #  Mouse callback function to capture clicks using zoomed-in refinement\n",
    "    def click_event(event, x, y, _flags, _params):\n",
    "        nonlocal clicked_points, img_copy\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            initial_point = (x, y)\n",
    "            refined = zoom_click_refinement(img, initial_point)\n",
    "            clicked_points.append(refined)\n",
    "            update_display()\n",
    "            print(f\"Point selected: {refined}\")\n",
    "\n",
    "    cv2.namedWindow(\"Manual Annotation\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"Manual Annotation\", 1280, 720)\n",
    "    cv2.imshow(\"Manual Annotation\", img_copy)\n",
    "    cv2.setMouseCallback(\"Manual Annotation\", click_event)\n",
    "\n",
    "    print(\"Please click on the 4 outer corners of the chessboard in the following order:\")\n",
    "    print(\"1. Top-Left\")\n",
    "    print(\"2. Top-Right\")\n",
    "    print(\"3. Bottom-Right\")\n",
    "    print(\"4. Bottom-Left\")\n",
    "    print(\"Press 'u' to undo the last click. After 4 clicks, press 'a' to accept or 'u' to undo the final click.\")\n",
    "\n",
    "    while True:\n",
    "        cv2.imshow(\"Manual Annotation\", img_copy)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('u'):\n",
    "            if clicked_points:\n",
    "                clicked_points.pop()\n",
    "                update_display()\n",
    "                print(\"Undid the last click.\")\n",
    "        if len(clicked_points) == 4:\n",
    "            print(\"4 points have been selected. Press 'a' to accept these points, or 'u' to undo the final click.\")\n",
    "            key_confirm = cv2.waitKey(0) & 0xFF\n",
    "            if key_confirm == ord('a'):\n",
    "                break\n",
    "            elif key_confirm == ord('u'):\n",
    "                if clicked_points:\n",
    "                    clicked_points.pop()\n",
    "                    update_display()\n",
    "                    print(\"Undid the last click. Please click again.\")\n",
    "        if key == 27:  # Esc key\n",
    "            print(\"Manual annotation canceled. Not enough points selected.\")\n",
    "            break\n",
    "\n",
    "    cv2.destroyWindow(\"Manual Annotation\")\n",
    "\n",
    "    if len(clicked_points) == 4:\n",
    "        return clicked_points\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# Function that linearly interpolates all chessboard points from the given outer corners\n",
    "def interpolate_with_homography(corners, grid_size):\n",
    "    num_cols, num_rows = grid_size\n",
    "\n",
    "    # Define the ideal source points in a rectified coordinate system for the inner corners\n",
    "    src_points = np.array([\n",
    "        [0, 0],                     # top-left of inner corners\n",
    "        [num_cols - 1, 0],          # top-right of inner corners\n",
    "        [num_cols - 1, num_rows - 1],  # bottom-right\n",
    "        [0, num_rows - 1]           # bottom-left\n",
    "    ], dtype=np.float32)\n",
    "    dst_points = np.array(corners, dtype=np.float32)\n",
    "    H = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "\n",
    "    # Generate the full grid of points using a list comprehension and convert to a NumPy array\n",
    "    grid_points = np.array([[j, i] for i in range(num_rows) for j in range(num_cols)], dtype=np.float32)\n",
    "    \n",
    "    # Reshape grid_points to (num_rows, num_cols, 2)\n",
    "    grid_points = grid_points.reshape(num_rows, num_cols, 2)\n",
    "            \n",
    "    # Transform the full grid to image points using the homography\n",
    "    full_points = cv2.perspectiveTransform(grid_points.reshape(-1, 1, 2), H)\n",
    "    full_points = full_points.reshape(num_rows, num_cols, 2)\n",
    "    \n",
    "    # Extract only the inner points (exclude the outer rows and columns)\n",
    "    inner_points = full_points[1:-1, 1:-1, :]\n",
    "    return inner_points.reshape(-1, 2)\n",
    "\n",
    "# Function that determines whether the chessboard is placed vertically or horizontally\n",
    "def determine_grid_size(corners, horizontal_grid_size=11, vertical_grid_size=8):\n",
    "    tl = np.array(corners[0], dtype=np.float32)\n",
    "    tr = np.array(corners[1], dtype=np.float32)\n",
    "    bl = np.array(corners[3], dtype=np.float32)\n",
    "    width = np.linalg.norm(tr - tl)\n",
    "    height = np.linalg.norm(bl - tl)\n",
    "    if width >= height:\n",
    "        return (horizontal_grid_size, vertical_grid_size)\n",
    "    else:\n",
    "        return (vertical_grid_size, horizontal_grid_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process Each Training Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image: training_images/WIN_20250211_11_12_06_Pro.jpg\n",
      "Automatic corner detection succeeded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:35:55.659 python[58723:16866021] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-02-16 19:35:55.659 python[58723:16866021] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image: training_images/WIN_20250211_10_59_26_Pro.jpg\n",
      "Automatic corner detection succeeded.\n",
      "\n",
      "Processing image: training_images/WIN_20250213_09_15_48_Pro.jpg\n",
      "Automatic corner detection succeeded.\n",
      "\n",
      "Processing image: training_images/WIN_20250212_12_24_50_Pro.jpg\n",
      "Automatic corner detection succeeded.\n",
      "\n",
      "Processing image: training_images/WIN_20250212_12_24_40_Pro.jpg\n",
      "Automatic corner detection succeeded.\n",
      "\n",
      "Processing image: training_images/WIN_20250213_09_07_56_Pro.jpg\n",
      "Automatic corner detection failed; invoking manual annotation.\n",
      "Please click on the 4 outer corners of the chessboard in the following order:\n",
      "1. Top-Left\n",
      "2. Top-Right\n",
      "3. Bottom-Right\n",
      "4. Bottom-Left\n",
      "Press 'u' to undo the last click. After 4 clicks, press 'a' to accept or 'u' to undo the final click.\n",
      "Point selected: (98.25, 230.25)\n",
      "Point selected: (1661.0, 193.0)\n",
      "Point selected: (1357.75, 576.75)\n",
      "Point selected: (469.0, 605.75)\n",
      "4 points have been selected. Press 'a' to accept these points, or 'u' to undo the final click.\n",
      "\n",
      "Processing image: training_images\\WIN_20250213_08_13_18_Pro.jpg\n",
      "Automatic corner detection failed; invoking manual annotation.\n",
      "Please click on the 4 outer corners of the chessboard in the following order:\n",
      "1. Top-Left\n",
      "2. Top-Right\n",
      "3. Bottom-Right\n",
      "4. Bottom-Left\n",
      "Press 'u' to undo the last click. After 4 clicks, press 'a' to accept or 'u' to undo the final click.\n",
      "Point selected: (902.75, 572.25)\n",
      "Point selected: (1504.75, 252.5)\n",
      "Point selected: (1755.25, 602.0)\n",
      "Point selected: (915.0, 970.0)\n",
      "4 points have been selected. Press 'a' to accept these points, or 'u' to undo the final click.\n",
      "\n",
      "Processing image: training_images\\WIN_20250213_09_07_51_Pro.jpg\n",
      "Automatic corner detection failed; invoking manual annotation.\n",
      "Please click on the 4 outer corners of the chessboard in the following order:\n",
      "1. Top-Left\n",
      "2. Top-Right\n",
      "3. Bottom-Right\n",
      "4. Bottom-Left\n",
      "Press 'u' to undo the last click. After 4 clicks, press 'a' to accept or 'u' to undo the final click.\n",
      "Manual annotation canceled. Not enough points selected.\n",
      "Skipping image since manual annotation is not available.\n",
      "\n",
      "Processing image: training_images\\WIN_20250213_09_07_56_Pro.jpg\n",
      "Automatic corner detection failed; invoking manual annotation.\n",
      "Please click on the 4 outer corners of the chessboard in the following order:\n",
      "1. Top-Left\n",
      "2. Top-Right\n",
      "3. Bottom-Right\n",
      "4. Bottom-Left\n",
      "Press 'u' to undo the last click. After 4 clicks, press 'a' to accept or 'u' to undo the final click.\n",
      "Manual annotation canceled. Not enough points selected.\n",
      "Skipping image since manual annotation is not available.\n",
      "\n",
      "Processing image: training_images\\WIN_20250213_09_15_48_Pro.jpg\n",
      "Automatic corner detection succeeded.\n",
      "\n",
      "Processing image: training_images\\WIN_20250213_09_16_23_Pro.jpg\n",
      "Automatic corner detection failed; invoking manual annotation.\n",
      "Please click on the 4 outer corners of the chessboard in the following order:\n",
      "1. Top-Left\n",
      "2. Top-Right\n",
      "3. Bottom-Right\n",
      "4. Bottom-Left\n",
      "Press 'u' to undo the last click. After 4 clicks, press 'a' to accept or 'u' to undo the final click.\n",
      "Manual annotation canceled. Not enough points selected.\n",
      "Skipping image since manual annotation is not available.\n"
     ]
    }
   ],
   "source": [
    "for idx, fname in enumerate(training_files):\n",
    "    print(f\"\\nProcessing image: {fname}\")\n",
    "    img_train = cv2.imread(fname)\n",
    "    if img_train is None:\n",
    "        print(\"Failed to load image.\")\n",
    "        continue\n",
    "    # Attempt automatic corner detection\n",
    "    ret, corners = detect_corners_automatically(img_train, pattern_size)\n",
    "    \n",
    "    if ret:\n",
    "        print(\"Automatic corner detection succeeded.\")\n",
    "         # Refine corner positions for better accuracy\n",
    "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "        corners_refined = cv2.cornerSubPix(cv2.cvtColor(img_train, cv2.COLOR_BGR2GRAY), corners, (11, 11), (-1, -1), criteria)\n",
    "\n",
    "        # Add the refined corners and corresponding object points\n",
    "        object_points_all.append(objp)\n",
    "        image_points_all.append(corners_refined)\n",
    "\n",
    "        # Store these in the automatic lists\n",
    "        object_points_auto.append(objp)\n",
    "        image_points_auto.append(corners_refined)\n",
    "\n",
    "        # Draw the detected corners\n",
    "        img_auto = img_train.copy()\n",
    "        cv2.drawChessboardCorners(img_auto, pattern_size, corners_refined, ret)\n",
    "        cv2.namedWindow(\"Automatic Corners\", cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(\"Automatic Corners\", img_auto)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(\"Automatic corner detection failed; invoking manual annotation.\")\n",
    "        manual_corners = get_manual_corners(img_train)\n",
    "        if manual_corners is not None:\n",
    "            grid_size_manual = determine_grid_size(manual_corners, horizontal_grid_size=11, vertical_grid_size=8)\n",
    "            corners_manual_full = interpolate_with_homography(manual_corners, grid_size_manual)\n",
    "\n",
    "            # Add the refined corners and corresponding object points\n",
    "            object_points_all.append(objp)\n",
    "            image_points_all.append(corners_manual_full)\n",
    "\n",
    "            # Draw the detected corners\n",
    "            img_with_points = img_train.copy()\n",
    "            for pt in corners_manual_full:\n",
    "                x, y = int(pt[0]), int(pt[1])\n",
    "                cv2.circle(img_with_points, (x, y), 3, (255, 0, 0), -1)\n",
    "            cv2.namedWindow(\"Interpolated Points\", cv2.WINDOW_NORMAL)\n",
    "            cv2.resizeWindow(\"Interpolated Points\", 1280, 720)\n",
    "            cv2.imshow(\"Interpolated Points\", img_with_points)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyWindow(\"Interpolated Points\")\n",
    "        else:\n",
    "            print(\"Skipping image since manual annotation is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the final test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the final test image\n",
    "final_test_file = \"final_test.jpg\"\n",
    "img_final = cv2.imread(final_test_file)\n",
    "if img_final is None:\n",
    "    print(\"Error: Could not load final test image.\")\n",
    "else:\n",
    "    # Convert the image to grayscale\n",
    "    gray_final = cv2.cvtColor(img_final, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Attempt automatic corner detection using your previously defined function\n",
    "    ret, corners_final = detect_corners_automatically(gray_final, pattern_size)\n",
    "    \n",
    "    print(\"Final Test Image - Detection flag (ret):\", ret)\n",
    "    \n",
    "    if ret:\n",
    "        print(\"Automatic corner detection succeeded on the final test image.\")\n",
    "        # Refine the detected corners for better accuracy\n",
    "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "        corners_final_refined = cv2.cornerSubPix(gray_final, corners_final, (11, 11), (-1, -1), criteria)\n",
    "\n",
    "        # Add the refined corners and corresponding object points\n",
    "        object_points_all.append(objp)\n",
    "        image_points_all.append(corners_refined)\n",
    "        \n",
    "        # Also store these in the automatic lists\n",
    "        object_points_auto.append(objp)\n",
    "        image_points_auto.append(corners_refined)\n",
    "        \n",
    "        # Draw the detected corners on a copy of the final image\n",
    "        img_final_drawn = img_final.copy()\n",
    "        cv2.drawChessboardCorners(img_final_drawn, pattern_size, corners_final_refined, ret)\n",
    "        \n",
    "        # Display the final test image with detected corners\n",
    "        cv2.namedWindow(\"Final Test Automatic Detection\", cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(\"Final Test Automatic Detection\", img_final_drawn)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(\"Automatic corner detection failed on the final test image. Please check the image conditions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camera Calibration Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine image size\n",
    "img_example = cv2.imread(training_files[0])\n",
    "img_size = (img_example.shape[1], img_example.shape[0])\n",
    "print(\"\\nImage size (width x height):\", img_size)\n",
    "\n",
    "# Run 1: Use all training images\n",
    "ret1, cameraMatrix1, distCoeffs1, rvecs1, tvecs1 = cv2.calibrateCamera(\n",
    "    object_points_all, image_points_all, img_size, None, None)\n",
    "print(\"\\nRun 1 Calibration Results (All Images):\")\n",
    "print(\"Camera Matrix:\\n\", cameraMatrix1)\n",
    "print(\"Distortion Coefficients:\\n\", distCoeffs1)\n",
    "\n",
    "# Run 2: Use only 10 images with automatic corner detections\n",
    "if len(object_points_auto) >= 10:\n",
    "    objpoints_run2 = object_points_auto[:10]\n",
    "    imgpoints_run2 = image_points_auto[:10]\n",
    "else:\n",
    "    print(\"Not enough automatic images for Run 2; using available automatic images.\")\n",
    "    objpoints_run2 = object_points_auto\n",
    "    imgpoints_run2 = image_points_auto\n",
    "\n",
    "ret2, cameraMatrix2, distCoeffs2, rvecs2, tvecs2 = cv2.calibrateCamera(\n",
    "    objpoints_run2, imgpoints_run2, img_size, None, None)\n",
    "print(\"\\nRun 2 Calibration Results (10 Automatic Images):\")\n",
    "print(\"Camera Matrix:\\n\", cameraMatrix2)\n",
    "print(\"Distortion Coefficients:\\n\", distCoeffs2)\n",
    "\n",
    "# Run 3: Use only 5 images from the automatic ones\n",
    "if len(objpoints_run2) >= 5:\n",
    "    objpoints_run3 = objpoints_run2[:5]\n",
    "    imgpoints_run3 = imgpoints_run2[:5]\n",
    "else:\n",
    "    print(\"Not enough images for Run 3; using available images from Run 2.\")\n",
    "    objpoints_run3 = objpoints_run2\n",
    "    imgpoints_run3 = imgpoints_run2\n",
    "\n",
    "ret3, cameraMatrix3, distCoeffs3, rvecs3, tvecs3 = cv2.calibrateCamera(\n",
    "    objpoints_run3, imgpoints_run3, img_size, None, None)\n",
    "print(\"\\nRun 3 Calibration Results (5 Automatic Images):\")\n",
    "print(\"Camera Matrix:\\n\", cameraMatrix3)\n",
    "print(\"Distortion Coefficients:\\n\", distCoeffs3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the calibration (will take out when submitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (After calibration runs, for example, after Cell 4)\n",
    "\n",
    "# Re-read the first training image (or choose any other image that shows the chessboard)\n",
    "img = cv2.imread(training_files[4])\n",
    "if img is None:\n",
    "    print(\"Error: Could not load the training image for overlay.\")\n",
    "    exit()\n",
    "\n",
    "# Define 3D points for coordinate axes (length = 3 squares, for example)\n",
    "axis = np.float32([[3*square_size, 0, 0],\n",
    "                   [0, 3*square_size, 0],\n",
    "                   [0, 0, -3*square_size]]).reshape(-1, 3)\n",
    "\n",
    "# Use the rotation and translation vectors from one of the calibration images.\n",
    "# Here we use the first set from Run 1 (rvecs1[0] and tvecs1[0]).\n",
    "# Project the 3D axis points to the image plane using the first calibration image's pose.\n",
    "imgpts, _ = cv2.projectPoints(axis, rvecs1[4], tvecs1[4], cameraMatrix1, distCoeffs1)\n",
    "\n",
    "# Convert the reference corner (e.g., the first detected chessboard corner) to integer coordinates.\n",
    "corner = tuple(map(int, image_points_all[4][0].ravel()))\n",
    "\n",
    "# Convert the projected axis points to integer coordinates.\n",
    "x_axis = tuple(map(int, imgpts[0].ravel()))\n",
    "y_axis = tuple(map(int, imgpts[1].ravel()))\n",
    "z_axis = tuple(map(int, imgpts[2].ravel()))\n",
    "\n",
    "# Copy the image for drawing the axes.\n",
    "img_axes = img.copy()\n",
    "img_axes = cv2.line(img_axes, corner, x_axis, (255, 0, 0), 5)  # X-axis in blue\n",
    "img_axes = cv2.line(img_axes, corner, y_axis, (0, 255, 0), 5)  # Y-axis in green\n",
    "img_axes = cv2.line(img_axes, corner, z_axis, (0, 0, 255), 5)  # Z-axis in red\n",
    "\n",
    "cv2.namedWindow(\"3D Axes Overlay\", cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"3D Axes Overlay\", img_axes)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate color based on position and orientation\n",
    "def calculate_hsv_color(rvec, tvec, top_plane_normal=[0, 0, 1]):\n",
    "    # Calculate distance to camera (for intensity/value)\n",
    "    distance = np.linalg.norm(tvec)\n",
    "    value = max(0, 255 * (1 - distance/4))  # Linear scaling 0-4m to 255-0\n",
    "    \n",
    "    # Calculate angle between camera and top plane normal (for saturation)\n",
    "    R, _ = cv2.Rodrigues(rvec)\n",
    "    transformed_normal = R.dot(top_plane_normal)\n",
    "    angle = np.arccos(transformed_normal[2]) * 180/np.pi  # Angle in degrees\n",
    "    saturation = max(0, 255 * (1 - angle/45))  # Linear scaling 0-45deg to 255-0\n",
    "    \n",
    "    # Calculate hue based on relative position\n",
    "    # Using horizontal position (x-coordinate) for hue\n",
    "    hue = (np.arctan2(tvec[0][0], tvec[2][0]) + np.pi) * 180/np.pi\n",
    "    \n",
    "    return np.uint8([[[hue, saturation, value]]])\n",
    "\n",
    "\n",
    "# Function to draw cube and axes\n",
    "def draw_cube_and_axes(img, rvec, tvec, camera_matrix, dist_coeffs, square_size):\n",
    "    # Define 3D points for coordinate axes (length = 3 squares)\n",
    "    axis_length = 3 * square_size\n",
    "    axes = np.float32([[0,0,0], [axis_length,0,0], [0,axis_length,0], [0,0,-axis_length]])\n",
    "    \n",
    "    # Define cube points (2x2x2 squares)\n",
    "    cube_size = 2 * square_size\n",
    "    cube_points = np.float32([\n",
    "        [0,0,0], [cube_size,0,0], [cube_size,cube_size,0], [0,cube_size,0],\n",
    "        [0,0,-cube_size], [cube_size,0,-cube_size], \n",
    "        [cube_size,cube_size,-cube_size], [0,cube_size,-cube_size]\n",
    "    ])\n",
    "    \n",
    "    # Project points\n",
    "    imgpts_axes, _ = cv2.projectPoints(axes, rvec, tvec, camera_matrix, dist_coeffs)\n",
    "    imgpts_cube, _ = cv2.projectPoints(cube_points, rvec, tvec, camera_matrix, dist_coeffs)\n",
    "    \n",
    "    # Draw axes\n",
    "    origin = tuple(map(int, imgpts_axes[0].ravel()))\n",
    "    img = cv2.line(img, origin, tuple(map(int, imgpts_axes[1].ravel())), (255,0,0), 3)  # X axis\n",
    "    img = cv2.line(img, origin, tuple(map(int, imgpts_axes[2].ravel())), (0,255,0), 3)  # Y axis\n",
    "    img = cv2.line(img, origin, tuple(map(int, imgpts_axes[3].ravel())), (0,0,255), 3)  # Z axis\n",
    "    \n",
    "    # Draw cube\n",
    "    imgpts_cube = np.int32(imgpts_cube).reshape(-1,2)\n",
    "    \n",
    "    # Draw bottom face\n",
    "    img = cv2.drawContours(img, [imgpts_cube[:4]], -1, (0,255,0), 3)\n",
    "    \n",
    "    # Draw top face\n",
    "    img = cv2.drawContours(img, [imgpts_cube[4:]], -1, (0,255,0), 3)\n",
    "    \n",
    "    # Draw vertical edges\n",
    "    for i in range(4):\n",
    "        img = cv2.line(img, tuple(imgpts_cube[i]), tuple(imgpts_cube[i+4]), (0,255,0), 3)\n",
    "    \n",
    "    # Get color for top polygon based on position and orientation\n",
    "    hsv_color = calculate_hsv_color(rvec, tvec)\n",
    "    bgr_color = cv2.cvtColor(hsv_color, cv2.COLOR_HSV2BGR).squeeze()\n",
    "    \n",
    "    # Draw filled top polygon\n",
    "    top_face = imgpts_cube[4:].reshape((-1,1,2))\n",
    "    cv2.fillConvexPoly(img, top_face, bgr_color.tolist())\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "# Process test image with all three calibration results\n",
    "test_img = cv2.imread(\"final_test.jpg\")\n",
    "gray_test = cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
    "ret, corners = detect_corners_automatically(gray_test, pattern_size)\n",
    "\n",
    "if ret:\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "    corners = cv2.cornerSubPix(gray_test, corners, (11,11), (-1,-1), criteria)\n",
    "    \n",
    "    # Process with each calibration result\n",
    "    for run, (camera_matrix, dist_coeffs) in enumerate([\n",
    "        (cameraMatrix1, distCoeffs1),\n",
    "        (cameraMatrix2, distCoeffs2),\n",
    "        (cameraMatrix3, distCoeffs3)\n",
    "    ], 1):\n",
    "        # Find pose\n",
    "        _, rvec, tvec = cv2.solvePnP(objp, corners, camera_matrix, dist_coeffs)\n",
    "        \n",
    "        # Draw results\n",
    "        img_result = test_img.copy()\n",
    "        img_result = draw_cube_and_axes(img_result, rvec, tvec, camera_matrix, dist_coeffs, square_size)\n",
    "        \n",
    "        # Display result\n",
    "        cv2.namedWindow(f\"Run {run} Result\", cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(f\"Run {run} Result\", img_result)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Could not detect corners in test image automatically\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
